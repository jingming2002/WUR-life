# Advanced statistics review
# ç»Ÿè®¡ç¬¦å·å¤§å…¨ï¼ˆGitHub README å…¼å®¹ç‰ˆï¼‰

## ğŸ“Š åŸºç¡€æè¿°ç»Ÿè®¡

| ç¬¦å· | åç§° | å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------|------|
| n | æ ·æœ¬é‡ | è§‚æµ‹å€¼æ•°é‡ | n = 100 |
| N | æ€»ä½“å¤§å° | æ€»ä½“å…ƒç´ æ•°é‡ | N = 1000 |
| xÌ„ | æ ·æœ¬å‡å€¼ | æ ·æœ¬å¹³å‡å€¼ | xÌ„ = 25.3 |
| Î¼ | æ€»ä½“å‡å€¼ | æ€»ä½“å¹³å‡å€¼ | Î¼ = 30.1 |
| sÂ² | æ ·æœ¬æ–¹å·® | æ ·æœ¬ç¦»æ•£ç¨‹åº¦ | sÂ² = 16.5 |
| ÏƒÂ² | æ€»ä½“æ–¹å·® | æ€»ä½“ç¦»æ•£ç¨‹åº¦ | ÏƒÂ² = 18.2 |
| s | æ ·æœ¬æ ‡å‡†å·® | æ ·æœ¬æ ‡å‡†å·® | s = 4.06 |
| Ïƒ | æ€»ä½“æ ‡å‡†å·® | æ€»ä½“æ ‡å‡†å·® | Ïƒ = 4.27 |
| med | ä¸­ä½æ•° | ä¸­é—´å€¼ | med = 24 |
| mod | ä¼—æ•° | å‡ºç°æœ€é¢‘ç¹çš„å€¼ | mod = 23 |
| Qâ‚, Qâ‚‚, Qâ‚ƒ | å››åˆ†ä½æ•° | 25%, 50%, 75% åˆ†ä½æ•° | Qâ‚ = 20, Qâ‚‚ = 25, Qâ‚ƒ = 30 |
| IQR | å››åˆ†ä½è· | Qâ‚ƒ - Qâ‚ | IQR = 10 |

## ğŸ“ˆ ç›¸å…³ä¸å›å½’

| ç¬¦å· | åç§° | å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------|------|
| r | æ ·æœ¬ç›¸å…³ç³»æ•° | çº¿æ€§ç›¸å…³å¼ºåº¦ | r = 0.85 |
| Ï | æ€»ä½“ç›¸å…³ç³»æ•° | æ€»ä½“ç›¸å…³å¼ºåº¦ | Ï = 0.78 |
| R | å¤šé‡ç›¸å…³ç³»æ•° | å¤šå…ƒç›¸å…³ | R = 0.92 |
| RÂ² | å†³å®šç³»æ•° | è§£é‡Šæ–¹å·®æ¯”ä¾‹ | RÂ² = 0.64 |
| adj RÂ² | è°ƒæ•´å†³å®šç³»æ•° | è°ƒæ•´åçš„è§£é‡Šæ¯”ä¾‹ | adj RÂ² = 0.61 |
| Î²â‚€ | æˆªè·é¡¹ | å›å½’å¸¸æ•°é¡¹ | Î²â‚€ = 2.5 |
| Î²â‚, Î²â‚‚... | å›å½’ç³»æ•° | æ–œç‡å‚æ•° | Î²â‚ = 0.8, Î²â‚‚ = -0.3 |
| bâ‚€, bâ‚... | ä¼°è®¡ç³»æ•° | ç³»æ•°ä¼°è®¡å€¼ | bâ‚€ = 2.3, bâ‚ = 0.75 |
| Å· | é¢„æµ‹å€¼ | æ¨¡å‹é¢„æµ‹ç»“æœ | Å· = 25.3 |
| Îµ | è¯¯å·®é¡¹ | éšæœºè¯¯å·® | y = Î²â‚€ + Î²â‚x + Îµ |

## ğŸ¯ æ¦‚ç‡ä¸åˆ†å¸ƒ

| ç¬¦å· | åç§° | å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------|------|
| P(A) | æ¦‚ç‡ | äº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡ | P(A) = 0.05 |
| P(Aâ”‚B) | æ¡ä»¶æ¦‚ç‡ | Bå‘ç”Ÿæ—¶Açš„æ¦‚ç‡ | P(Aâ”‚B) = 0.3 |
| E(X) | æœŸæœ›å€¼ | éšæœºå˜é‡æœŸæœ› | E(X) = Î¼ |
| Var(X) | æ–¹å·® | éšæœºå˜é‡æ–¹å·® | Var(X) = ÏƒÂ² |
| Cov(X,Y) | åæ–¹å·® | ä¸¤ä¸ªå˜é‡ååŒå˜åŒ– | Cov(X,Y) = 12.5 |
| âˆ¼ | æœä»åˆ†å¸ƒ | æ¦‚ç‡åˆ†å¸ƒ | X âˆ¼ N(0,1) |
| âˆ | æ­£æ¯”äº | æˆæ¯”ä¾‹å…³ç³» | y âˆ x |

## ğŸ“‹ æ¦‚ç‡åˆ†å¸ƒç¬¦å·

| åˆ†å¸ƒ | ç¬¦å· | å‚æ•° | ç¤ºä¾‹ |
|------|------|------|------|
| æ­£æ€åˆ†å¸ƒ | N(Î¼, ÏƒÂ²) | å‡å€¼, æ–¹å·® | X âˆ¼ N(50, 25) |
| æ ‡å‡†æ­£æ€ | N(0, 1) | æ ‡å‡†æ­£æ€ | Z âˆ¼ N(0, 1) |
| tåˆ†å¸ƒ | t(df) | è‡ªç”±åº¦ | T âˆ¼ t(15) |
| Fåˆ†å¸ƒ | F(dfâ‚, dfâ‚‚) | åˆ†å­åˆ†æ¯è‡ªç”±åº¦ | F âˆ¼ F(3, 20) |
| å¡æ–¹åˆ†å¸ƒ | Ï‡Â²(df) | è‡ªç”±åº¦ | Ï‡Â² âˆ¼ Ï‡Â²(5) |
| äºŒé¡¹åˆ†å¸ƒ | Bin(n, p) | è¯•éªŒæ¬¡æ•°, æˆåŠŸæ¦‚ç‡ | X âˆ¼ Bin(10, 0.5) |
| æ³Šæ¾åˆ†å¸ƒ | Pois(Î») | å‘ç”Ÿç‡ | X âˆ¼ Pois(3) |
| æŒ‡æ•°åˆ†å¸ƒ | Exp(Î») | é€Ÿç‡å‚æ•° | X âˆ¼ Exp(0.5) |

## ğŸ” å‡è®¾æ£€éªŒ

| ç¬¦å· | åç§° | å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------|------|
| Hâ‚€ | é›¶å‡è®¾ | å¾…æ£€éªŒçš„å‡è®¾ | Hâ‚€: Î¼ = 100 |
| Hâ‚ | å¤‡æ‹©å‡è®¾ | æ›¿ä»£å‡è®¾ | Hâ‚: Î¼ â‰  100 |
| Hâ‚ | å¤‡æ‹©å‡è®¾ | åŒHâ‚ | Hâ‚: Î¼ > 100 |
| Î± | æ˜¾è‘—æ€§æ°´å¹³ | ç¬¬ä¸€ç±»é”™è¯¯æ¦‚ç‡ | Î± = 0.05 |
| Î² | ç¬¬äºŒç±»é”™è¯¯æ¦‚ç‡ | é”™è¯¯æ¥å—Hâ‚€çš„æ¦‚ç‡ | Î² = 0.20 |
| 1-Î² | æ£€éªŒåŠŸæ•ˆ | æ­£ç¡®æ‹’ç»Hâ‚€çš„æ¦‚ç‡ | 1-Î² = 0.80 |
| p | på€¼ | è§‚å¯Ÿåˆ°çš„æç«¯æ¦‚ç‡ | p = 0.023 |
| CI | ç½®ä¿¡åŒºé—´ | å‚æ•°ä¼°è®¡åŒºé—´ | 95% CI: [45.2, 54.8] |

## ğŸ“ æ£€éªŒç»Ÿè®¡é‡

| ç¬¦å· | åç§° | å…¬å¼/å«ä¹‰ | ç¤ºä¾‹ |
|------|------|------------|------|
| z | zç»Ÿè®¡é‡ | (xÌ„ - Î¼â‚€)/(Ïƒ/âˆšn) | z = 2.15 |
| t | tç»Ÿè®¡é‡ | (xÌ„ - Î¼â‚€)/(s/âˆšn) | t(25) = 2.31 |
| F | Fç»Ÿè®¡é‡ | æ–¹å·®æ¯” | F(3,20) = 4.25 |
| Ï‡Â² | å¡æ–¹ç»Ÿè®¡é‡ | æ‹Ÿåˆä¼˜åº¦æ£€éªŒ | Ï‡Â²(5) = 12.3 |
| U | Mann-Whitney U | éå‚æ•°æ£€éªŒ | U = 45 |

## ğŸ§® æ•°å­¦è¿ç®—ç¬¦

| ç¬¦å· | åç§° | ç¤ºä¾‹ |
|------|------|------|
| Î£ | æ±‚å’Œ | Î£xáµ¢ = xâ‚ + xâ‚‚ + ... + xâ‚™ |
| Î  | æ±‚ç§¯ | Î xáµ¢ = xâ‚ Ã— xâ‚‚ Ã— ... Ã— xâ‚™ |
| âˆ« | ç§¯åˆ† | âˆ«f(x)dx |
| âˆ‚ | åå¯¼æ•° | âˆ‚f/âˆ‚x |
| Î” | å·®åˆ† | Î”x = xâ‚‚ - xâ‚ |
| lim | æé™ | lim(xâ†’0)f(x) |
| âˆ | æ— ç©·å¤§ | n â†’ âˆ |

## âš–ï¸ æ¯”è¾ƒè¿ç®—ç¬¦

| ç¬¦å· | åç§° | ç¤ºä¾‹ |
|------|------|------|
| = | ç­‰äº | Î¼ = 100 |
| â‰  | ä¸ç­‰äº | Î¼ â‰  100 |
| < | å°äº | p < 0.05 |
| > | å¤§äº | n > 30 |
| â‰¤ | å°äºç­‰äº | Î± â‰¤ 0.05 |
| â‰¥ | å¤§äºç­‰äº | åŠŸæ•ˆ â‰¥ 0.80 |
| â‰ˆ | çº¦ç­‰äº | Ï€ â‰ˆ 3.14159 |
| â‰¡ | æ’ç­‰äº | a â‰¡ b |

## ğŸ”¢ ä¸Šä¸‹æ ‡æ•°å­—

| æ•°å­— | ä¸Šæ ‡ | ä¸‹æ ‡ | ä½¿ç”¨ç¤ºä¾‹ |
|------|------|------|----------|
| 0 | â° | â‚€ | xâ°, xâ‚€ |
| 1 | Â¹ | â‚ | Î²Â¹, xâ‚ |
| 2 | Â² | â‚‚ | RÂ², xâ‚‚ |
| 3 | Â³ | â‚ƒ | 2Â³, Î²â‚ƒ |
| 4 | â´ | â‚„ | nâ´, xâ‚„ |
| 5 | âµ | â‚… | Ï‡Â²âµ, yâ‚… |
| 6 | â¶ | â‚† | tâ¶, zâ‚† |
| 7 | â· | â‚‡ | Fâ·, wâ‚‡ |
| 8 | â¸ | â‚ˆ | Ïƒâ¸, vâ‚ˆ |
| 9 | â¹ | â‚‰ | pâ¹, uâ‚‰ |




## General idea about a population
--- Question about population  
--- Take sample   
--- Test hypothesis in the sample   
--- Take into account variation among samples  
--- Draw a conclusion about the population

## Confidence interval (CI)  
An interval that is expected to typically contain the parameter being estimated    
CI=Point EstimateÂ±(t critical)Ã—(Standard Error)  

Point Estimate: Exp. point estimate of popilation mean(&mu;) is sample's mean(x&#772;) 
 
T critical: Width of interval and Df(degrees of freedom) 
 
Standard Error: Size and variation of the sample  

## t-test
Degrees of freedom determine the shape of t-distribution; larger df will cause it more normality, if df â†’ âˆ, it will be exactly a normal distribution.  

### Single-sample t-test
Sample's mean compared with known &mu;   
1. H<sub>0</sub>: x&#772; = &mu;  
H<sub>a</sub>: x&#772; != &mu;  or  x&#772; > &mu; or x&#772; < &mu;  
2. t = (xÌ„ - Î¼â‚€) / (s/âˆšn)
3. Under H<sub>0</sub>, t~t<sub>df = (n - 1)</sub>
4. Under H<sub>a</sub>, T.S tends to smaller or larger values than under H<sub>0</sub>
5. Using left, right, or two-tailed p-value
6. t = T.S
7. p-value compared with &alpha;
8. Conclusion
### Independent two-sample t-test
***SAME VARIANCE!!!!!!!!!!!!!***  
Comparing the two samples' means  
1. H<sub>0</sub>: &mu;<sub>1</sub>=&mu;<sub>2</sub>  
   H<sub>0</sub>: &mu;<sub>1</sub>!=&mu;<sub>2</sub> (Smaller, larger or just differ)
2. t= (xÌ„â‚ - xÌ„â‚‚) / [sâ‚š Ã— âˆš(1/nâ‚ + 1/nâ‚‚)]  
sâ‚š= âˆš{ [ (nâ‚ - 1)sâ‚Â² + (nâ‚‚ - 1)sâ‚‚Â² ] / (nâ‚ + nâ‚‚ - 2) }  
df = nâ‚ + nâ‚‚ - 2
3. Under H<sub>0</sub>, t~t<sub>df</sub>
4. Under H<sub>a</sub>, T.S tends to smaller or larger values than under H<sub>0</sub>
5. Using left, right, or two-tailed p-value
6. t = T.S
7. p-value compared with &alpha;
8. Conclusion

#### Levene's test
This is close to F-test; they share a common statistic  
F = MSB/MSW  
MSB = [Mean<sub>A</sub>-Mean<sub>all</sub>)+(Mean<sub>B</sub>-Mean<sub>all</sub>)]/(k-1)  
MSW = [Î£(x<sub>i</sub>-xÌ„)<sup>2</sup>+Î£(x<sub>j</sub>-xÌ„<sub>1</sub>)<sup>2</sup>]/(N-k)  
N is nr of total units, k stands for nr of samples
#### Welch's t-test
Normally, we do not have two samples with exactly the same variances, so Welch's t-test could be applied.  
It is essentially the same as the t-test, but offers more conservative calculations and a lower probability of false positivity.
1. H<sub>0</sub>: &mu;<sub>1</sub>=&mu;<sub>2</sub>  
   H<sub>0</sub>: &mu;<sub>1</sub>!=&mu;<sub>2</sub> (Smaller, larger or just differ)
2. t= (xÌ„â‚ - xÌ„â‚‚) / [sâ‚š Ã— âˆš(1/nâ‚ + 1/nâ‚‚)]  
sâ‚š= âˆš{ [ (nâ‚ - 1)sâ‚Â² + (nâ‚‚ - 1)sâ‚‚Â² ] / (nâ‚ + nâ‚‚ - 2) }  
***df = [ (sâ‚Â²/nâ‚ + sâ‚‚Â²/nâ‚‚)Â² ] / [ (sâ‚Â²/nâ‚)Â²/(nâ‚-1) + (sâ‚‚Â²/nâ‚‚)Â²/(nâ‚‚-1) ]***
3. Under H<sub>0</sub>, t~t<sub>df</sub>
4. Under H<sub>a</sub>, T.S tends to smaller or larger values than under H<sub>0</sub>
5. Using left, right, or two-tailed p-value
6. t = T.S
7. p-value compared with &alpha;
8. Conclusion

### Paired-sample t-test
Check there is any difference between one sample in two conditions.
1. H<sub>0</sub>: &mu;<sub>1</sub>=&mu;<sub>2</sub>  
   H<sub>0</sub>: &mu;<sub>1</sub>!=&mu;<sub>2</sub> (Smaller, larger or just differ)
2. t= dÌ„ / (s_d / âˆšn)
3. Under H<sub>0</sub>, t~t<sub>df</sub>
4. Under H<sub>a</sub>, T.S tends to smaller or larger values than under H<sub>0</sub>
5. Using left, right, or two-tailed p-value
6. t = T.S
7. p-value compared with &alpha;
8. Conclusion

